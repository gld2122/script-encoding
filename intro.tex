\section{Introduction}

Language is fundamentally a spoken phenomenon, but ever since the dawn of
writing, the specter of written form has pulled a psychological trick over
viewers. We view it as "the real thing" because we can hold it in our hands,
roll it around, and sniff the paper it's written on. We view it as "better",
since its author spent painstaking hours beneath the candlelight, honing each
sentence to discover how far they might drive the limits of their craft. I'm
looking at you, "Aliens For Dinner" \parencite{spinner94}. And let's not forget
about other classic hits like "The Bible", "The Qur'an", and "The Corpus Juris
Civilis". In all seriousness, the central position of written texts in law and
religion underpins the prestige of writing.

In many ways, writing is the province of the "few", a tool for the upper
classes. Although this situation has equalized in developed countries somewhat
given increased literacy rates, (ie. the interaction with and production of
written media are an essential aspect of modern life) it remains true today that
harnessing writing \textit{on the large scale} (publication) remains out of
reach for most people. Powerful organizations control traditional means of
publication, including publishing houses, news outlets, and governments.  The
Internet is changing the situation somewhat. Internet fora like blogs, social
media sites, and web pages are a low-cost way of presenting work to the wider
world. Although having this work viewed outside your own network is still
difficult on Internet platforms, hosting sites at the least give individuals'
work a venue and a chance of being accessed by others.

But then the Internet introduces equal access problems of its own. For one,
there is the obvious issue of global disparities regarding access to technology
and data. These disparities exist between developed and developing countries, as
well as among different classes within the same country. Alternatively the
Internet may be levelling the language in which we access written media. Due to
the early development of computers and networking in the United States and to
the economic power of English, English gained a tangible head start as the
language of the Web. This is rapidly changing in the case of major languages,
like Spanish, French, and Chinese as Unicode-based technologies make
representing a wide array of languages much easier than in the past. The most
recent study by Fundaci√≥n Redes y Desarollo found 32\% of Internet content to be
written in English, followed by 18.0\% in Chinese, 8.0\% in Spanish, and 6.5\%
in French \parencite{funredes17}.

The real linguistic losers on the Internet are small minority languages. By this
term, I do not mean extremely isolated or nonstandard spoken languages.
Instead, I am referring to languages with a written tradition, but which are not
widely used in official state-level contexts. Examples include languages like
Galician, Sindhi, Assamese, Tamazight, and Sardinian. These languages do not
benefit from state resources for developing digital linguistic infrastructure.
Likewise, speakers of regional languages, especially in developing countries,
may be negatively impacted by the global digital divide. Finally, there is the
ever-present threat that English and other large national languages will devour
the world's local languages. 

First I will briefly discuss the rationale and goals of Unicode for building
multilingual digital architecture. Then we will look at two case studies
(Vietnam and Myanmar) to see how the choice of encoding standards can support or
discourage the digital growth for languages. In Vietnam, Unicode enjoys wide
support; this makes Vietnamese documents compatible with the wider world and
provides an extensible framework for the inclusion of Vietnam's ethnic
languages. In Myanmar, however, Unicode support lags behind due to the
popularity of a legacy encoding called Zawgyi; this situation threatens
Myanmar's compatibility with modern software and the representation of Myanmar's
ethnic languages.
